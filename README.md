# ğŸš• Taxi Trip Streaming Pipeline â€” AWS Architecture

This project provides a **fault-tolerant, real-time streaming pipeline** for taxi trip events. Built on AWS, it processes start-trip and end-trip events through **Kinesis** and **Lambda**, stores trip state in **DynamoDB**, and enables error handling and relay recovery through **SNS**, **SQS**, and **AWS Glue**.


This project provides a **faultâ€‘tolerant, realâ€‘time streaming pipeline** for taxi trip events.  
Built on **AWS**, it:

- Processes startâ€‘trip and endâ€‘trip events using **Kinesis** and **Lambda**
- Persists trip state in **DynamoDB**
- Ensures error handling and recovery through **SNS**, **SQS**, and **AWS Glue**

---

# ğŸ“š Table of Contents

- [Overview](#overview)
- [High-Level Architecture](#high-level-architecture)
- [Components](#components)
- [Sequence Diagrams](#sequence-diagrams)
  - [Start-Trip Event Flow](#1ï¸âƒ£-start-trip-event-flow)
  - [End-Trip Event Flow](#2ï¸âƒ£-end-trip-event-flow)
  - [Glue Replay Recovery Flow](#3ï¸âƒ£-glue-replay-recovery-flow)
- [Glue Replay Job](#glue-replay-job)
- [Data Flow Summary](#data-flow-summary)
- [Repository Structure](#repository-structure)
- [Future Enhancements](#future-enhancements)

---

# âš¡ Overview

This project implements a **streaming taxi trip pipeline** designed for:

- Real-time ingestion  
- Scalable event processing  
- Fault-tolerant updates  
- Exactly-onceâ€“like behavior  

The pipeline uses the following AWS components:

- **Kinesis Streams** â€“ start & end event ingestion  
- **Lambda Functions** â€“ real-time event processors  
- **DynamoDB** â€“ trip state database  
- **SNS** â€“ invalid data notifications  
- **SQS** â€“ buffering of failed updates  
- **AWS Glue** â€“ batch recovery of failed writes  

Together, these components guarantee **eventual consistency** and **no lost events**.

---

# ğŸ—ï¸ High-Level Architecture

```mermaid
flowchart LR
    subgraph Ingestion Layer
        A1[Start-Trip\nProducers] --> KS1[Kinesis Stream\nstart-trip-stream]
        A2[End-Trip\nProducers] --> KS2[Kinesis Stream\nend-trip-stream]
    end

    subgraph Processing Layer
        KS1 --> L1[Lambda\nstart-taxi-trips]
        KS2 --> L2[Lambda\nend-taxi-trips]
    end

    subgraph Storage & State
        DDB[(DynamoDB\n taxi_trip_details)]
    end

    subgraph Error Handling
        SNS[(SNS Topic\nInvalid-taxi-trips)]
        SQS[(SQS Queue\nfailed-updated-trips)]
    end

    subgraph Recovery Layer
        Glue[Glue Job\nReplay Failed Trips]
    end

    %% start trip flow
    L1 -->|Valid start event| DDB
    L1 -->|Invalid event| SNS

    %% end trip flow
    L2 -->|Valid end event| DDB
    L2 -->|DynamoDB Write Error| SQS

    %% glue recovery flow
    SQS -->|Batch Read| Glue -->|Replay Updates| DDB
    Glue -->|Delete on Success| SQS
```

---

# ğŸ§© Components

### **1. Amazon Kinesis Streams**
Two dedicated streams:
- `start-trip-stream`
- `end-trip-stream`

These provide high-throughput ingestion and ordered delivery.

---

### **2. AWS Lambda Functions**

#### **start-taxi-trips**
- Validates start-trip events  
- Writes initial trip record to DynamoDB  
- Sends invalid events to SNS  

#### **end-taxi-trips**
- Processes end-trip events  
- Updates DynamoDB with completion details  
- On error â†’ sends event to SQS (`failed-updated-trips`)

---

### **3. DynamoDB â€” `taxi_trip_details`**
Stores the authoritative record of every trip:

| Attribute | Purpose |
|----------|----------|
| `trip_id` | Primary key |
| `start_time`, `end_time` | Timestamps |
| `pickup/dropoff location` | Coordinates |
| `fare` | Trip cost |
| `status` | STARTED / COMPLETED |

---

### **4. SQS â€” Failed Update Buffer**
`failed-updated-trips` queue stores events that the end-trip Lambda could not write to DynamoDB.

This ensures *no event is ever lost*.

---

### **5. AWS SNS â€” Invalid Data Notifications**
All malformed or inconsistent start-trip events are published to:
```
SNS Topic: Invalid-taxi-trips
```
An email subscription receives alerts for inspection.

---

### **6. AWS Glue Replay Job**
A Python job performing:

- Batch SQS reads  
- Idempotent DynamoDB updates  
- Guaranteed deletion of SQS messages only after success  

---

# ğŸ§µ Sequence Diagrams

---

## 1ï¸âƒ£ Start-Trip Event Flow

```mermaid
sequenceDiagram
    autonumber

    participant Producer as Trip Source
    participant Kinesis as start-trip-stream
    participant Lambda as start-taxi-trips Lambda
    participant DDB as DynamoDB<br>taxi_trip_details
    participant SNS as SNS Topic<br>Invalid-taxi-trips

    Producer ->> Kinesis: PutRecord(start-trip event)
    Kinesis ->> Lambda: Trigger event batch
    Lambda ->> Lambda: Validate start-trip payload

    alt Valid start-trip
        Lambda ->> DDB: PutItem / UpdateItem<br>status="STARTED"
    else Invalid event
        Lambda ->> SNS: Publish notification
    end
```

---

## 2ï¸âƒ£ End-Trip Event Flow

```mermaid
sequenceDiagram
    autonumber

    participant Producer as Trip Source
    participant Kinesis as end-trip-stream
    participant Lambda as end-taxi-trips Lambda
    participant DDB as DynamoDB<br>taxi_trip_details
    participant SQS as SQS Queue<br>failed-updated-trips

    Producer ->> Kinesis: PutRecord(end-trip event)
    Kinesis ->> Lambda: Trigger event batch
    Lambda ->> Lambda: Validate end-trip event

    alt DynamoDB update succeeds
        Lambda ->> DDB: UpdateItem<br>status="ENDED", fare, timestamps
    else DynamoDB update fails
        Lambda ->> SQS: SendMessage(original event)
    end
```

---

## 3ï¸âƒ£ Glue Replay Recovery Flow

```mermaid
sequenceDiagram
    autonumber

    participant Glue as Glue Job<br>replay_failed_trips()
    participant SQS as SQS Queue<br>failed-updated-trips
    participant DDB as DynamoDB<br>taxi_trip_details

    loop Until SQS empty
        Glue ->> SQS: ReceiveMessage(max 10)
        SQS -->> Glue: Messages(batch)

        alt No messages returned
            Glue ->> Glue: Exit loop<br>(Queue empty)
        end

        loop For each message
            Glue ->> Glue: Parse record JSON
            Glue ->> DDB: UpdateItem<br>(idempotent update)

            alt Update successful
                Glue ->> SQS: DeleteMessage
            else Update failed
                Glue ->> Glue: Log failure<br>(message reappears later)
            end
        end
    end
```

---

# ğŸ” Glue Replay Job

The glue job (`taxi_trip_glue_replay.py`) implements:

### âœ” Decimal-safe JSON parsing  
DynamoDB requires numeric precision, so JSON numbers are parsed as `Decimal`.

### âœ” Validation  
Every replayed record must include `trip_id`.

### âœ” Dynamic UpdateExpression generation  
The job builds DynamoDB update expressions dynamically based on fields present.

### âœ” Idempotent updates  
If the same event is replayed multiple times, it simply overwrites the same trip record safely.

### âœ” Safe delete-on-success behavior  
Messages are removed from SQS *only after* DynamoDB write success.

---

# ğŸ”„ Data Flow Summary

```
Start-trip â†’ Kinesis â†’ Lambda â†’ DynamoDB
End-trip   â†’ Kinesis â†’ Lambda â†’ DynamoDB (âœ“ success)
End-trip   â†’ Kinesis â†’ Lambda â†’ SQS (âœ— failure)
SQS â†’ Glue Replay â†’ DynamoDB (recovered)
```

This ensures:

- No data loss  
- Automatic recovery  
- Reliable end-to-end consistency  

---

# ğŸ“ Repository Structure

```
.
â”œâ”€â”€ TaxiTripResourcesAWS-template.yaml     # CloudFormation IaC stack
â”œâ”€â”€ taxi_trip_glue_replay.py               # Glue job for batch recovery
â”œâ”€â”€ README.md                              # Documentation (this file)
â””â”€â”€ diagrams/                              # Optional: saved PNG/SVG diagrams
```

---

# ğŸš€ Future Enhancements

- Add CI/CD pipeline (GitHub Actions, CodePipeline)  
- Add unit tests for Lambda and Glue  
- Add CloudWatch alarm dashboards  
- Integrate DynamoDB Streams for real-time analytics  
- Introduce schema registry for versioned trip events  

---
